# Legal QA Chatbot - Há»‡ thá»‘ng TÆ° váº¥n PhÃ¡p luáº­t Viá»‡t Nam

## ğŸš€ Tá»•ng quan

**Legal QA Chatbot** lÃ  má»™t há»‡ thá»‘ng chatbot thÃ´ng minh sá»­ dá»¥ng AI Ä‘á»ƒ tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i cÃ´ng nghá»‡ RAG (Retrieval Augmented Generation) vÃ  cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng á»Ÿ nhiá»u cháº¿ Ä‘á»™ khÃ¡c nhau tÃ¹y theo nhu cáº§u sá»­ dá»¥ng.

### ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- **ğŸ¤– Chatbot AI**: TÆ° váº¥n phÃ¡p luáº­t tá»± Ä‘á»™ng vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao
- **ğŸ“š RAG System**: TÃ¬m kiáº¿m vÃ  truy xuáº¥t thÃ´ng tin tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t
- **âš¡ Äa cháº¿ Ä‘á»™**: Simple LLM, Full RAG, vÃ  Auto-start
- **ğŸŒ Web Interface**: Giao diá»‡n Streamlit thÃ¢n thiá»‡n vÃ  trá»±c quan
- **ğŸ“Š Monitoring**: Há»‡ thá»‘ng logging vÃ  thá»‘ng kÃª chi tiáº¿t
- **ğŸ” Hybrid Search**: Káº¿t há»£p dense vÃ  sparse vectors Ä‘á»ƒ tÃ¬m kiáº¿m tá»‘i Æ°u

### ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚   Qdrant DB     â”‚    â”‚   Ollama LLM    â”‚
â”‚   Web Interface â”‚â—„â”€â”€â–ºâ”‚   Vector Store  â”‚â—„â”€â”€â–ºâ”‚   Language      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   Model         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚    â”‚   Document      â”‚    â”‚   Generated     â”‚
â”‚   Processing    â”‚    â”‚   Retrieval     â”‚    â”‚   Response      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n má»m cáº§n thiáº¿t

- **Python**: >= 3.10
- **Docker**: Äá»ƒ cháº¡y Qdrant vector database
- **Ollama**: Äá»ƒ cháº¡y language models
- **Git**: Äá»ƒ clone repository

### Pháº§n cá»©ng khuyáº¿n nghá»‹

- **RAM**: Tá»‘i thiá»ƒu 8GB (khuyáº¿n nghá»‹ 16GB+)
- **Storage**: Tá»‘i thiá»ƒu 10GB trá»‘ng
- **CPU**: Multi-core processor

## ğŸ› ï¸ CÃ i Ä‘áº·t Environment

### 1. Clone Repository

```bash
git clone <repository-url>
cd Fine-tune-LegalVN
```

### 2. CÃ i Ä‘áº·t Python Dependencies

#### PhÆ°Æ¡ng Ã¡n A: Sá»­ dá»¥ng uv (Khuyáº¿n nghá»‹)

```bash
# CÃ i Ä‘áº·t uv náº¿u chÆ°a cÃ³
pip install uv

# CÃ i Ä‘áº·t dependencies
uv sync
```

#### PhÆ°Æ¡ng Ã¡n B: Sá»­ dá»¥ng pip

```bash
# Táº¡o virtual environment
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# CÃ i Ä‘áº·t dependencies
pip install -e .
```

### 3. CÃ i Ä‘áº·t Ollama

#### Windows:
```bash
# Download vÃ  cÃ i Ä‘áº·t tá»« https://ollama.ai
# Hoáº·c sá»­ dá»¥ng winget
winget install Ollama.Ollama
```

#### Linux/Mac:
```bash
# CÃ i Ä‘áº·t Ollama
curl -fsSL https://ollama.ai/install.sh | sh
```

### 4. CÃ i Ä‘áº·t Docker

#### Windows:
- Download Docker Desktop tá»« https://docker.com
- Hoáº·c sá»­ dá»¥ng winget: `winget install Docker.DockerDesktop`

#### Linux:
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install docker.io docker-compose

# Start Docker service
sudo systemctl start docker
sudo systemctl enable docker
```

## ğŸ³ CÃ i Ä‘áº·t vÃ  Cháº¡y Docker Services

### 1. Khá»Ÿi Ä‘á»™ng Qdrant Vector Database

```bash
# Cháº¡y Qdrant container
docker run -d \
  --name qdrant-legal-qa \
  -p 6333:6333 \
  -v qdrant_storage:/qdrant/storage \
  qdrant/qdrant

# Kiá»ƒm tra Qdrant Ä‘ang cháº¡y
docker ps | grep qdrant

# Test káº¿t ná»‘i
curl http://localhost:6333/collections
```

### 2. CÃ i Ä‘áº·t Ollama Models

```bash
# Khá»Ÿi Ä‘á»™ng Ollama service
ollama serve

# CÃ i Ä‘áº·t model cho Simple LLM (app_simple.py)
ollama pull gemma3:1b

# CÃ i Ä‘áº·t model cho Full RAG (app.py)
ollama pull llama3.1:8b

# Kiá»ƒm tra models Ä‘Ã£ cÃ i
ollama list
```

### 3. Táº¡o Vector Database Collection

```bash
# Cháº¡y Jupyter notebook Ä‘á»ƒ táº¡o collection
jupyter notebook notebooks/index_database.ipynb

# Hoáº·c cháº¡y script Python tÆ°Æ¡ng tá»±
python scripts/setup_database.py
```

## ğŸš€ HÆ°á»›ng dáº«n Cháº¡y App

### PhÆ°Æ¡ng Ã¡n 1: Simple LLM (Dá»… nháº¥t - KhÃ´ng cáº§n Qdrant)

```bash
# BÆ°á»›c 1: CÃ i Ä‘áº·t model nhá»
ollama pull gemma3:1b

# BÆ°á»›c 2: Cháº¡y á»©ng dá»¥ng
streamlit run app_simple.py
```

**TÃ­nh nÄƒng:**
- âœ… KhÃ´ng cáº§n Qdrant database
- âœ… Setup nhanh vÃ  Ä‘Æ¡n giáº£n
- âœ… Sá»­ dá»¥ng kiáº¿n thá»©c cÃ³ sáºµn cá»§a LLM
- âš ï¸ Cháº¥t lÆ°á»£ng tráº£ lá»i phá»¥ thuá»™c vÃ o training data cá»§a model

### PhÆ°Æ¡ng Ã¡n 2: Full RAG (Äáº§y Ä‘á»§ tÃ­nh nÄƒng)

```bash
# BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Qdrant
docker run -d --name qdrant-legal-qa -p 6333:6333 qdrant/qdrant

# BÆ°á»›c 2: CÃ i Ä‘áº·t model lá»›n
ollama pull llama3.1:8b

# BÆ°á»›c 3: Táº¡o collection vÃ  index dá»¯ liá»‡u
# Cháº¡y notebook: notebooks/index_database.ipynb

# BÆ°á»›c 4: Cháº¡y á»©ng dá»¥ng
streamlit run app.py
```

**TÃ­nh nÄƒng:**
- âœ… RAG system vá»›i vector database
- âœ… Hybrid search (dense + sparse)
- âœ… Reranking Ä‘á»ƒ tá»‘i Æ°u káº¿t quáº£
- âœ… Nguá»“n tham kháº£o chi tiáº¿t
- âš ï¸ Setup phá»©c táº¡p hÆ¡n

### PhÆ°Æ¡ng Ã¡n 3: Auto-start (Tá»± Ä‘á»™ng hÃ³a)

```bash
# Cháº¡y script tá»± Ä‘á»™ng
python start_app.py
```

**TÃ­nh nÄƒng:**
- âœ… Tá»± Ä‘á»™ng kiá»ƒm tra vÃ  khá»Ÿi Ä‘á»™ng services
- âœ… Tá»± Ä‘á»™ng cÃ i Ä‘áº·t models náº¿u thiáº¿u
- âœ… Tá»± Ä‘á»™ng start Streamlit app
- âœ… Error handling vÃ  troubleshooting


## ğŸ¯ CÃ¡ch sá»­ dá»¥ng

### 1. Khá»Ÿi táº¡o há»‡ thá»‘ng

- Má»Ÿ á»©ng dá»¥ng trong browser (thÆ°á»ng lÃ  `http://localhost:8501`)
- Click nÃºt **"ğŸš€ Khá»Ÿi táº¡o há»‡ thá»‘ng"** trong sidebar
- Äá»£i há»‡ thá»‘ng load cÃ¡c models (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)

### 2. Äáº·t cÃ¢u há»i

- Nháº­p cÃ¢u há»i phÃ¡p luáº­t vÃ o chat input
- Hoáº·c click vÃ o **cÃ¢u há»i máº«u** trong sidebar
- Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng tÃ¬m kiáº¿m vÃ  táº¡o cÃ¢u tráº£ lá»i

### 3. TÃ¹y chá»‰nh tham sá»‘

- **Cháº¿ Ä‘á»™ hiá»‡u suáº¥t**: Fast, Balanced, Accurate
- **Sá»‘ lÆ°á»£ng tÃ i liá»‡u**: Äiá»u chá»‰nh top_k vÃ  rerank_top_k
- **Cache**: Báº­t/táº¯t cache Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™

### 4. Xem nguá»“n tham kháº£o

- Click **"ğŸ“š Nguá»“n tham kháº£o"** Ä‘á»ƒ xem tÃ i liá»‡u gá»‘c
- Kiá»ƒm tra Ä‘iá»ƒm sá»‘ Ä‘á»™ liÃªn quan
- Xem chi tiáº¿t context Ä‘Æ°á»£c sá»­ dá»¥ng

## ğŸ”§ Cáº¥u hÃ¬nh

### Thay Ä‘á»•i Models

Trong file `app.py`:

```python
# DÃ²ng 34-37
dense_model_name = "sentence-transformers/all-MiniLM-L6-v2"
sparse_model_name = "Qdrant/bm25"
rerank_model_name = "jinaai/jina-reranker-v2-base-multilingual"
llm_model_name = "llama3.1:8b"  # Thay Ä‘á»•i model á»Ÿ Ä‘Ã¢y
```

### Thay Ä‘á»•i Collection

```python
# DÃ²ng 158
self.collection_name = "thue-phi-le-phi_all-MiniLM-L6-v2"
```

### Thay Ä‘á»•i Prompt Template

```python
# Trong method generate_answer()
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam...
    # TÃ¹y chá»‰nh template á»Ÿ Ä‘Ã¢y
    """
)
```

## ğŸš¨ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. **"Qdrant connection failed"**

```bash
# Kiá»ƒm tra Qdrant Ä‘ang cháº¡y
docker ps | grep qdrant

# Khá»Ÿi Ä‘á»™ng Qdrant
docker run -d --name qdrant-legal-qa -p 6333:6333 qdrant/qdrant

# Test káº¿t ná»‘i
curl http://localhost:6333/collections
```

#### 2. **"Collection not found"**

```bash
# Cháº¡y notebook Ä‘á»ƒ táº¡o collection
jupyter notebook notebooks/index_database.ipynb

# Hoáº·c kiá»ƒm tra collections cÃ³ sáºµn
curl http://localhost:6333/collections
```

#### 3. **"Ollama model not found"**

```bash
# Kiá»ƒm tra models
ollama list

# CÃ i Ä‘áº·t model
ollama pull llama3.1:8b  # cho app.py
ollama pull gemma3:1b   # nháº¹ vÃ  nhanh hÆ¡n

# Khá»Ÿi Ä‘á»™ng Ollama
ollama serve
```

#### 4. **Performance issues**

- Giáº£m `top_k` vÃ  `rerank_top_k` trong sidebar
- Sá»­ dá»¥ng `app_simple.py` thay vÃ¬ `app.py`
- Sá»­ dá»¥ng model nhá» hÆ¡n (gemma3:1b)
- TÄƒng timeout trong QdrantClient

#### 5. **Docker khÃ´ng cháº¡y Ä‘Æ°á»£c**

```bash
# Windows: Khá»Ÿi Ä‘á»™ng Docker Desktop
# Linux: Start Docker service
sudo systemctl start docker

# Kiá»ƒm tra Docker
docker --version
docker ps
```

### Debug vá»›i Logs

```bash
# Xem logs real-time
tail -f legal_qa_full.log
tail -f legal_qa_simple.log

# TÃ¬m lá»—i
grep "ERROR" legal_qa_full.log
grep "Failed to initialize" legal_qa_full.log

# Theo dÃµi performance
grep "Generated answer length" legal_qa_full.log
grep "Retrieved.*documents" legal_qa_full.log
```

## ğŸ“ˆ Monitoring vÃ  Logs

### Logging System

- **File logs**: `legal_qa_full.log`, `legal_qa_simple.log`
- **Console output**: Real-time vá»›i UTF-8 encoding
- **Log levels**: INFO, WARNING, ERROR
- **Format**: Timestamp, module, level, message

### Metrics Ä‘Æ°á»£c theo dÃµi

- Sá»‘ lÆ°á»£ng tÃ i liá»‡u trong collection
- Sá»‘ tin nháº¯n trong session
- Thá»i gian khá»Ÿi táº¡o há»‡ thá»‘ng
- Thá»i gian táº¡o cÃ¢u tráº£ lá»i
- Sá»‘ lÆ°á»£ng documents retrieved
- Context length vÃ  answer length

## ğŸ”„ Updates & Roadmap

### ÄÃ£ hoÃ n thÃ nh

- âœ… **3 phiÃªn báº£n á»©ng dá»¥ng** (Simple LLM, Full RAG, Auto-start)
- âœ… **Logging system** chi tiáº¿t vá»›i UTF-8 encoding
- âœ… **Click-to-use sample questions**
- âœ… **Error handling** vÃ  troubleshooting guides
- âœ… **Model configuration** linh hoáº¡t
- âœ… **Performance optimization** vá»›i caching

### TÃ­nh nÄƒng sáº¯p tá»›i

1**File upload**: Cho phÃ©p upload tÃ i liá»‡u phÃ¡p luáº­t
2**Export chat**: Xuáº¥t lá»‹ch sá»­ chat ra PDF
3**Multi-language**: Há»— trá»£ tiáº¿ng Anh
4**Admin panel**: Quáº£n lÃ½ collection vÃ  models
5**API endpoints**: REST API cho integration

### Cáº£i thiá»‡n performance

1. **Caching**: Cache embeddings vÃ  responses
2. **Async**: Sá»­ dá»¥ng async/await cho I/O operations
3. **Batch processing**: Xá»­ lÃ½ nhiá»u queries cÃ¹ng lÃºc
4. **Model optimization**: Quantization vÃ  optimization

## ğŸ“ Support

### Khi gáº·p váº¥n Ä‘á»

1. **Kiá»ƒm tra logs** trong terminal vÃ  file logs
2. **Verify services** Ä‘ang cháº¡y (Ollama, Qdrant)
3. **Test tá»«ng component** riÃªng biá»‡t
4. **Check dependencies** versions


### Full Setup 

```bash
# Setup Ä‘áº§y Ä‘á»§ vá»›i RAG
docker run -d --name qdrant-legal-qa -p 6333:6333 qdrant/qdrant
ollama pull llama3.1:8b
# Cháº¡y notebooks/index_database.ipynb Ä‘á»ƒ táº¡o collection
streamlit run app.py
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Streamlit Documentation](https://docs.streamlit.io/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Ollama Documentation](https://ollama.ai/docs)
- [LangChain Documentation](https://python.langchain.com/)
- [Sentence Transformers](https://www.sbert.net/)

---

**Happy Chatting! âš–ï¸ğŸ¤–**

*Chá»n phiÃªn báº£n phÃ¹ há»£p vá»›i nhu cáº§u cá»§a báº¡n: Simple LLM cho setup nhanh, Full RAG cho cháº¥t lÆ°á»£ng cao!*
